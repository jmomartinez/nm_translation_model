{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# fra.txt Data Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Total Data Length = 150,000 sequence pairs (per data source)\n",
    "path = '../../../Datasets/fra.txt'\n",
    "temp,text=0,[]\n",
    "for line in open(path,mode='r',encoding='utf-8'):\n",
    "    if temp>5000:\n",
    "        break\n",
    "    text.append(line)\n",
    "    temp+=1\n",
    "text = np.asarray(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print('Text Shape:{}'.format(text.shape))\n",
    "print('Text Subset:\\n{}'.format(text[:10]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Text Shape:(5001,)\n",
      "Text Subset:\n",
      "['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\\n'\n",
      " 'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)\\n'\n",
      " 'Go.\\tBouge !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)\\n'\n",
      " 'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\\n'\n",
      " 'Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\\n'\n",
      " 'Run!\\tCours\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\\n'\n",
      " 'Run!\\tCourez\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\\n'\n",
      " 'Run!\\tPrenez vos jambes Ã  vos cous !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077449 (sacredceltic)\\n'\n",
      " 'Run!\\tFile !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077454 (sacredceltic)\\n'\n",
      " 'Run!\\tFilez !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077455 (sacredceltic)\\n']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observations\n",
    "1. Data is 150,000 in length, likely don't want to use all of it, for time & computational purposes (i.e. could take very long to train the model locally)\n",
    "2. Data is structured in pairs of sequences separated by tabs (\\t)\n",
    "3. Data has punctuation (.,!,etc.), needs to be removed bc the model doesn't like special characters\n",
    "4. Data should be lower cased for similar reasons\n",
    "5. We only need the Fre-Eng sequences so we can get rid of any other data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Test Cleaner\n",
    "seq = text[0].split('\\t')\n",
    "seq = '|'.join(seq[:1] + seq[1:2])\n",
    "seq = re.sub(r\"[^a-zA-Z|]\",'',seq)\n",
    "seq = seq.lower().split('|')\n",
    "print(seq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['go', 'va']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "st = 'cool this is a new sentence with this more than one word and it is'\n",
    "st2 = 'new sentences with new words and interesting effects'\n",
    "st = st.lower().split(' ')\n",
    "st2 = st2.lower().split(' ')\n",
    "a = [st,st2]\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(a)\n",
    "tk.word_index"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'new': 1,\n",
       " 'this': 2,\n",
       " 'is': 3,\n",
       " 'with': 4,\n",
       " 'and': 5,\n",
       " 'cool': 6,\n",
       " 'a': 7,\n",
       " 'sentence': 8,\n",
       " 'more': 9,\n",
       " 'than': 10,\n",
       " 'one': 11,\n",
       " 'word': 12,\n",
       " 'it': 13,\n",
       " 'sentences': 14,\n",
       " 'words': 15,\n",
       " 'interesting': 16,\n",
       " 'effects': 17}"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "tk.texts_to_sequences(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[6, 2, 3, 7, 1, 8, 4, 2, 9, 10, 11, 12, 5, 13, 3],\n",
       " [1, 14, 4, 1, 15, 5, 16, 17]]"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('nmt_model': conda)"
  },
  "interpreter": {
   "hash": "7ff15d897114af843c8c9d910afb9c6fa674e4533f8e5548b1d50ec16e6cd528"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}