{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Sequences import SequenceEncoding, SequenceDecoding\n",
    "from ModelArgs import ModelArgs\n",
    "from TranslationModel import TranslationModel\n",
    "from keras.models import load_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Data Length = 150,000 sequence pairs (per data source)\n",
    "def load_data(path:str):\n",
    "    text = []\n",
    "    with open(path,mode='r',encoding='utf-8') as txt_file:\n",
    "        for i,line in enumerate(txt_file):\n",
    "            text.append(line)\n",
    "            if i>100:\n",
    "                break\n",
    "    return np.asarray(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Shape:(102,)\n",
      "Text Subset:\n",
      "['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\\n'\n",
      " 'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)\\n'\n",
      " 'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)\\n'\n",
      " 'Go.\\tBouge !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)\\n'\n",
      " 'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\\n'\n",
      " 'Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\\n'\n",
      " 'Run!\\tCours\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\\n'\n",
      " 'Run!\\tCourez\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\\n'\n",
      " 'Run!\\tPrenez vos jambes Ã  vos cous !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077449 (sacredceltic)\\n'\n",
      " 'Run!\\tFile !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077454 (sacredceltic)\\n']\n"
     ]
    }
   ],
   "source": [
    "data = load_data('fra.txt')\n",
    "print('Text Shape:{}'.format(data.shape))\n",
    "print('Text Subset:\\n{}'.format(data[:10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "1. Data is 150,000 in length, likely don't want to use all of it, for time & computational purposes\n",
    "2. Data is structured in pairs of sequences separated by tabs (\\t)\n",
    "3. Data has punctuation (.,!,etc.), needs to be removed because the model doesn't like special characters\n",
    "4. Data should be lower cased for similar reasons\n",
    "5. We only need the Fre-Eng sequences so we can get rid of any other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cleaner (V1)\n",
    "seq = text[0].split('\\t')\n",
    "seq = '|'.join(seq[:1] + seq[1:2])\n",
    "seq = re.sub(r\"[^a-zA-Z|]\",'',seq)\n",
    "seq = seq.lower().split('|')\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'va']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative: Avoids joining and re-splitting string by special character\n",
    "seq = text[0].strip().split('\\t')\n",
    "eng = re.sub(r\"[^a-zA-Z]\",'',seq[0])\n",
    "fre = re.sub(r\"[^a-zA-Z]\",'',seq[1])\n",
    "seq = [eng.lower(),fre.lower()]\n",
    "seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208906\n",
      "Max IN: 139, Max OUT: 139\n"
     ]
    }
   ],
   "source": [
    "path = 'fra.txt'\n",
    "encoding_obj = SequenceEncoding(path)\n",
    "encoding_obj.load_text()\n",
    "vocab_metadata = encoding_obj.get_vocab_metadata()\n",
    "x_train, x_test, y_train, y_test = encoding_obj.process_data(vocab_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_in_length': 139,\n",
       " 'in_vocab_size': 16164,\n",
       " 'in_tok': <keras.preprocessing.text.Tokenizer at 0x243b9f0d040>,\n",
       " 'out_vocab_size': 30905,\n",
       " 'max_out_length': 139,\n",
       " 'out_tok': <keras.preprocessing.text.Tokenizer at 0x243b9f0d310>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167124, 139)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(167124, 139)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  11,  122,   57, ...,    0,    0,    0],\n",
       "       [  96,   22,   19, ...,    0,    0,    0],\n",
       "       [   7,  670,    3, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  22,    2,  407, ...,    0,    0,    0],\n",
       "       [   1,  207,    7, ...,    0,    0,    0],\n",
       "       [   4,  376, 8762, ...,    0,    0,    0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  11,    5,   34, ...,    0,    0,    0],\n",
       "       [  71,   44,   99, ...,    0,    0,    0],\n",
       "       [  10,    8,  459, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  19,  172,   31, ...,    0,    0,    0],\n",
       "       [ 233,    4,   10, ...,    0,    0,    0],\n",
       "       [   7, 1095,    8, ...,    0,    0,    0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train.shape, y_train.shape)\n",
    "display(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40000, 23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   2,   26,   16, ...,    0,    0,    0],\n",
       "       [   1, 1495, 1191, ...,    0,    0,    0],\n",
       "       [   1,   44,  643, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 136,    4, 1711, ...,    0,    0,    0],\n",
       "       [  23,    6,   32, ...,    0,    0,    0],\n",
       "       [  18,    3,  259, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,   55,   48, ...,    0,    0,    0],\n",
       "       [   2,  738,  525, ...,    0,    0,    0],\n",
       "       [   2,   10,  234, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  99,    3, 2610, ...,    0,    0,    0],\n",
       "       [  22,    7,  925, ...,    0,    0,    0],\n",
       "       [  43,    8,   56, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train.shape, y_train.shape)\n",
    "display(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, loss = 'rmsprop', 'sparse_categorical_crossentropy'\n",
    "epochs, batch_size = 5, 1_000\n",
    "args = ModelArgs(optimizer,loss,epochs,batch_size,vocab_metadata['in_vocab_size'],\n",
    "vocab_metadata['out_vocab_size'],vocab_metadata['max_in_length'],vocab_metadata['max_out_length'], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmt_obj = TranslationModel(args, x_train,y_train)\n",
    "model = nmt_obj.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 139, 32)           506816    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 139, 32)          0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 139, 32)           8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 139, 30224)        997392    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,520,848\n",
      "Trainable params: 1,520,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path: str, batch_size: int, epochs: int, line_limit = None):\n",
    "    encoding_obj = SequenceEncoding(path, line_limit= line_limit)\n",
    "    encoding_obj.load_text()\n",
    "    vocab_metadata = encoding_obj.get_vocab_metadata()\n",
    "    x_train, x_test, y_train, y_test = encoding_obj.process_data(vocab_metadata, output_tokenizers=True)\n",
    "\n",
    "    optimizer, loss = 'rmsprop', 'sparse_categorical_crossentropy'\n",
    "    args = ModelArgs(optimizer,loss,epochs,batch_size,vocab_metadata['in_vocab_size'],\n",
    "    vocab_metadata['out_vocab_size'],vocab_metadata['max_in_length'],vocab_metadata['max_out_length'], validation_split=0.15)\n",
    "    \n",
    "    nmt_obj = TranslationModel(args, x_train, y_train)\n",
    "    model = nmt_obj.create_model()\n",
    "    history = nmt_obj.train(model)\n",
    "    return history, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max IN: 8, Max OUT: 27\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.05798, saving model to best_model.keras\n",
      "340/340 - 65s - loss: 2.5545 - val_loss: 1.0580 - 65s/epoch - 191ms/step\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_loss improved from 1.05798 to 0.97803, saving model to best_model.keras\n",
      "340/340 - 58s - loss: 1.0106 - val_loss: 0.9780 - 58s/epoch - 171ms/step\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_loss improved from 0.97803 to 0.94922, saving model to best_model.keras\n",
      "340/340 - 59s - loss: 0.9581 - val_loss: 0.9492 - 59s/epoch - 173ms/step\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_loss improved from 0.94922 to 0.93347, saving model to best_model.keras\n",
      "340/340 - 59s - loss: 0.9332 - val_loss: 0.9335 - 59s/epoch - 175ms/step\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_loss improved from 0.93347 to 0.91635, saving model to best_model.keras\n",
      "340/340 - 59s - loss: 0.9142 - val_loss: 0.9164 - 59s/epoch - 175ms/step\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_loss improved from 0.91635 to 0.90218, saving model to best_model.keras\n",
      "340/340 - 59s - loss: 0.8976 - val_loss: 0.9022 - 59s/epoch - 174ms/step\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: val_loss improved from 0.90218 to 0.88369, saving model to best_model.keras\n",
      "340/340 - 59s - loss: 0.8806 - val_loss: 0.8837 - 59s/epoch - 174ms/step\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: val_loss improved from 0.88369 to 0.86940, saving model to best_model.keras\n",
      "340/340 - 59s - loss: 0.8613 - val_loss: 0.8694 - 59s/epoch - 174ms/step\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: val_loss improved from 0.86940 to 0.85425, saving model to best_model.keras\n",
      "340/340 - 59s - loss: 0.8442 - val_loss: 0.8543 - 59s/epoch - 175ms/step\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 10: val_loss improved from 0.85425 to 0.84271, saving model to best_model.keras\n",
      "340/340 - 60s - loss: 0.8298 - val_loss: 0.8427 - 60s/epoch - 175ms/step\n"
     ]
    }
   ],
   "source": [
    "history, x_test, y_test = main('fra.txt', batch_size=100, epochs=10, line_limit=50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243296f21c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_dec = SequenceDecoding('best_model.keras',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 32)             108640    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 27, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 27, 32)            8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27, 7070)          233310    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 358,590\n",
      "Trainable params: 358,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d73fafa7411f345213dba5bf7fc6bd077db64df13d94ce657c5bc7aed332c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
