{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from SequenceEncoding import SequenceEncoding\n",
    "from ModelArgs import ModelArgs\n",
    "from TranslationModel import TranslationModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Data Length = 150,000 sequence pairs (per data source)\n",
    "def load_data(path:str):\n",
    "    text = []\n",
    "    with open(path,mode='r',encoding='utf-8') as txt_file:\n",
    "        for i,line in enumerate(txt_file):\n",
    "            text.append(line)\n",
    "            if i>100:\n",
    "                break\n",
    "    return np.asarray(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Shape:(102,)\n",
      "Text Subset:\n",
      "['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\\n'\n",
      " 'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)\\n'\n",
      " 'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)\\n'\n",
      " 'Go.\\tBouge !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)\\n'\n",
      " 'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\\n'\n",
      " 'Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\\n'\n",
      " 'Run!\\tCours\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\\n'\n",
      " 'Run!\\tCourez\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\\n'\n",
      " 'Run!\\tPrenez vos jambes Ã  vos cous !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077449 (sacredceltic)\\n'\n",
      " 'Run!\\tFile !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077454 (sacredceltic)\\n']\n"
     ]
    }
   ],
   "source": [
    "data = load_data('fra.txt')\n",
    "print('Text Shape:{}'.format(data.shape))\n",
    "print('Text Subset:\\n{}'.format(data[:10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "1. Data is 150,000 in length, likely don't want to use all of it, for time & computational purposes\n",
    "2. Data is structured in pairs of sequences separated by tabs (\\t)\n",
    "3. Data has punctuation (.,!,etc.), needs to be removed because the model doesn't like special characters\n",
    "4. Data should be lower cased for similar reasons\n",
    "5. We only need the Fre-Eng sequences so we can get rid of any other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'va']\n"
     ]
    }
   ],
   "source": [
    "# Test Cleaner (V1)\n",
    "seq = text[0].split('\\t')\n",
    "seq = '|'.join(seq[:1] + seq[1:2])\n",
    "seq = re.sub(r\"[^a-zA-Z|]\",'',seq)\n",
    "seq = seq.lower().split('|')\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'va']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative: Avoids joining and re-splitting string by special character\n",
    "seq = text[0].strip().split('\\t')\n",
    "eng = re.sub(r\"[^a-zA-Z]\",'',seq[0])\n",
    "fre = re.sub(r\"[^a-zA-Z]\",'',seq[1])\n",
    "seq = [eng.lower(),fre.lower()]\n",
    "seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max IN: 139, Max OUT: 139\n"
     ]
    }
   ],
   "source": [
    "path = 'fra.txt'\n",
    "encoding_obj = SequenceEncoding(path)\n",
    "encoding_obj.load_text()\n",
    "vocab_metadata = encoding_obj.get_vocab_metadata()\n",
    "x_train, x_test, y_train, y_test = encoding_obj.process_data(vocab_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_in_length': 139,\n",
       " 'in_vocab_size': 15838,\n",
       " 'in_tok': <keras.preprocessing.text.Tokenizer at 0x7f88a1456a00>,\n",
       " 'out_vocab_size': 30224,\n",
       " 'max_out_length': 139,\n",
       " 'out_tok': <keras.preprocessing.text.Tokenizer at 0x7f88a1456ee0>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40000, 23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   2,   26,   16, ...,    0,    0,    0],\n",
       "       [   1, 1495, 1191, ...,    0,    0,    0],\n",
       "       [   1,   44,  643, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 136,    4, 1711, ...,    0,    0,    0],\n",
       "       [  23,    6,   32, ...,    0,    0,    0],\n",
       "       [  18,    3,  259, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,   55,   48, ...,    0,    0,    0],\n",
       "       [   2,  738,  525, ...,    0,    0,    0],\n",
       "       [   2,   10,  234, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  99,    3, 2610, ...,    0,    0,    0],\n",
       "       [  22,    7,  925, ...,    0,    0,    0],\n",
       "       [  43,    8,   56, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train.shape, y_train.shape)\n",
    "display(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, loss = 'rmsprop', 'sparse_categorical_crossentropy'\n",
    "epochs, batch_size = 5, 1_000\n",
    "args = ModelArgs(optimizer,loss,epochs,batch_size,vocab_metadata['in_vocab_size'],\n",
    "vocab_metadata['out_vocab_size'],vocab_metadata['max_in_length'],vocab_metadata['max_out_length'], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmt_obj = TranslationModel(args, x_train,y_train)\n",
    "model = nmt_obj.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 139, 32)           506816    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 139, 32)          0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 139, 32)           8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 139, 30224)        997392    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,520,848\n",
      "Trainable params: 1,520,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "trained_model = nmt_obj.train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d73fafa7411f345213dba5bf7fc6bd077db64df13d94ce657c5bc7aed332c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
