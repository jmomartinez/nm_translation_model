{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 12:08:54.567729: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from SequenceEncoding import SequenceEncoding\n",
    "from ModelArgs import ModelArgs\n",
    "from TranslationModel import TranslationModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Data Length = 150,000 sequence pairs (per data source)\n",
    "def load_data(path:str):\n",
    "    text = []\n",
    "    with open(path,mode='r',encoding='utf-8') as txt_file:\n",
    "        for i,line in enumerate(txt_file):\n",
    "            text.append(line)\n",
    "            if i>100:\n",
    "                break\n",
    "    return np.asarray(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Shape:(102,)\n",
      "Text Subset:\n",
      "['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\\n'\n",
      " 'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)\\n'\n",
      " 'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)\\n'\n",
      " 'Go.\\tBouge !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)\\n'\n",
      " 'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\\n'\n",
      " 'Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\\n'\n",
      " 'Run!\\tCours\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\\n'\n",
      " 'Run!\\tCourez\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\\n'\n",
      " 'Run!\\tPrenez vos jambes Ã  vos cous !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077449 (sacredceltic)\\n'\n",
      " 'Run!\\tFile !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077454 (sacredceltic)\\n']\n"
     ]
    }
   ],
   "source": [
    "data = load_data('fra.txt')\n",
    "print('Text Shape:{}'.format(data.shape))\n",
    "print('Text Subset:\\n{}'.format(data[:10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "1. Data is 150,000 in length, likely don't want to use all of it, for time & computational purposes\n",
    "2. Data is structured in pairs of sequences separated by tabs (\\t)\n",
    "3. Data has punctuation (.,!,etc.), needs to be removed because the model doesn't like special characters\n",
    "4. Data should be lower cased for similar reasons\n",
    "5. We only need the Fre-Eng sequences so we can get rid of any other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'va']\n"
     ]
    }
   ],
   "source": [
    "# Test Cleaner (V1)\n",
    "seq = text[0].split('\\t')\n",
    "seq = '|'.join(seq[:1] + seq[1:2])\n",
    "seq = re.sub(r\"[^a-zA-Z|]\",'',seq)\n",
    "seq = seq.lower().split('|')\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'va']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative: Avoids joining and re-splitting string by special character\n",
    "seq = text[0].strip().split('\\t')\n",
    "eng = re.sub(r\"[^a-zA-Z]\",'',seq[0])\n",
    "fre = re.sub(r\"[^a-zA-Z]\",'',seq[1])\n",
    "seq = [eng.lower(),fre.lower()]\n",
    "seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max IN: 139, Max OUT: 139\n"
     ]
    }
   ],
   "source": [
    "path = 'fra.txt'\n",
    "encoding_obj = SequenceEncoding(path)\n",
    "encoding_obj.load_text()\n",
    "vocab_metadata = encoding_obj.get_vocab_metadata()\n",
    "x_train, x_test, y_train, y_test = encoding_obj.process_data(vocab_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_in_length': 139,\n",
       " 'in_vocab_size': 15838,\n",
       " 'in_tok': <keras.preprocessing.text.Tokenizer at 0x7f88a1456a00>,\n",
       " 'out_vocab_size': 30224,\n",
       " 'max_out_length': 139,\n",
       " 'out_tok': <keras.preprocessing.text.Tokenizer at 0x7f88a1456ee0>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40000, 23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   2,   26,   16, ...,    0,    0,    0],\n",
       "       [   1, 1495, 1191, ...,    0,    0,    0],\n",
       "       [   1,   44,  643, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 136,    4, 1711, ...,    0,    0,    0],\n",
       "       [  23,    6,   32, ...,    0,    0,    0],\n",
       "       [  18,    3,  259, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,   55,   48, ...,    0,    0,    0],\n",
       "       [   2,  738,  525, ...,    0,    0,    0],\n",
       "       [   2,   10,  234, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  99,    3, 2610, ...,    0,    0,    0],\n",
       "       [  22,    7,  925, ...,    0,    0,    0],\n",
       "       [  43,    8,   56, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train.shape, y_train.shape)\n",
    "display(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, loss = 'rmsprop', 'sparse_categorical_crossentropy'\n",
    "epochs, batch_size = 5, 1_000\n",
    "args = ModelArgs(optimizer,loss,epochs,batch_size,vocab_metadata['in_vocab_size'],\n",
    "vocab_metadata['out_vocab_size'],vocab_metadata['max_in_length'],vocab_metadata['max_out_length'], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmt_obj = TranslationModel(args, x_train,y_train)\n",
    "model = nmt_obj.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 139, 32)           506816    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 139, 32)          0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 139, 32)           8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 139, 30224)        997392    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,520,848\n",
      "Trainable params: 1,520,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path: str, line_limit = None):\n",
    "    encoding_obj = SequenceEncoding(path, line_limit= line_limit)\n",
    "    encoding_obj.load_text()\n",
    "    vocab_metadata = encoding_obj.get_vocab_metadata()\n",
    "    x_train, x_test, y_train, y_test = encoding_obj.process_data(vocab_metadata)\n",
    "\n",
    "    optimizer, loss = 'rmsprop', 'sparse_categorical_crossentropy'\n",
    "    epochs, batch_size = 10, 1_000\n",
    "    args = ModelArgs(optimizer,loss,epochs,batch_size,vocab_metadata['in_vocab_size'],\n",
    "    vocab_metadata['out_vocab_size'],vocab_metadata['max_in_length'],vocab_metadata['max_out_length'], validation_split=0.15)\n",
    "    \n",
    "    nmt_obj = TranslationModel(args, x_train,y_train)\n",
    "    model = nmt_obj.create_model()\n",
    "    trained_model = nmt_obj.train(model)\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max IN: 8, Max OUT: 27\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 7.77155, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 22s - loss: 8.6084 - val_loss: 7.7716 - 22s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_loss improved from 7.77155 to 6.30517, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 18s - loss: 7.0723 - val_loss: 6.3052 - 18s/epoch - 1s/step\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_loss improved from 6.30517 to 5.10715, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 18s - loss: 5.7479 - val_loss: 5.1072 - 18s/epoch - 1s/step\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_loss improved from 5.10715 to 4.09920, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 19s - loss: 4.6372 - val_loss: 4.0992 - 19s/epoch - 1s/step\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_loss improved from 4.09920 to 3.24096, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 18s - loss: 3.6986 - val_loss: 3.2410 - 18s/epoch - 1s/step\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_loss improved from 3.24096 to 2.52032, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 18s - loss: 2.9004 - val_loss: 2.5203 - 18s/epoch - 1s/step\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: val_loss improved from 2.52032 to 1.96408, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 18s - loss: 2.2499 - val_loss: 1.9641 - 18s/epoch - 1s/step\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: val_loss improved from 1.96408 to 1.58888, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 18s - loss: 1.7749 - val_loss: 1.5889 - 18s/epoch - 1s/step\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: val_loss improved from 1.58888 to 1.36542, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 18s - loss: 1.4718 - val_loss: 1.3654 - 18s/epoch - 1s/step\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 10: val_loss improved from 1.36542 to 1.23685, saving model to best_model.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 18s - loss: 1.2957 - val_loss: 1.2369 - 18s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "trained_model = main('fra.txt', 20_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d73fafa7411f345213dba5bf7fc6bd077db64df13d94ce657c5bc7aed332c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
